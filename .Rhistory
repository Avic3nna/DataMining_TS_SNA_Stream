#exploring data
freq <- colSums(as.matrix(dtm))   #organize terms by frequency
length(freq)
head(table(freq), 10) #check the less occuring words - top number is frequency of appearing, bottom number the number of words
tail(table(freq), 10) #check the most occurring words
dtms <- removeSparseTerms(dtm, 0.1) #remove sparse - less frequent items, matrix that is only 10% empty space
print(dtms)
freq <- colSums(as.matrix(dtms))
freq
# table after removing sparse terms
freq <- colSums(as.matrix(dtms))
print(freq)
print(findFreqTerms(dtm, lowfreq=30)) #show words that appear 30 or more times
#plotting
# word frequencies
library(ggplot2)
wf <- data.frame(word=names(freq), freq=freq)
p <- ggplot(subset(wf, freq>50), aes(word, freq))
p <- p + geom_bar(stat="identity")
p <- p + theme(axis.text.x=element_text(angle=45, hjust=1))
print(p)
#or ordered...
p <- ggplot(subset(wf, freq>50), aes(x = reorder(word, -freq), y = freq)) +
geom_bar(stat = "identity") +
theme(axis.text.x=element_text(angle=45, hjust=1))
print(p)
#find correlations between terms
findAssocs(dtm, c("will" , "american"), corlimit=0.85) #find correlations between words
#cloud of words
library(SnowballC)
library(wordcloud)
library(RColorBrewer)
freq = data.frame(sort(colSums(as.matrix(dtm)), decreasing=TRUE))
wordcloud::wordcloud(rownames(freq), freq[,1], scale=c(4, .1), max.words=50, colors=brewer.pal(6, "Dark2")) #most frequently used 50 words
#plot words that occur at least 50 times
wordcloud::wordcloud(rownames(freq), freq[,1], scale=c(4, .1), min.freq=25, colors=brewer.pal(6, "Dark2"))  #words used at least 25 times or more
#clustering by term similarity
#hierarchical
dtmss <- removeSparseTerms(dtm, 0.15) # This makes a matrix that is only 15% empty space, maximum.
print(dtmss)
library(cluster)
d <- dist(t(dtmss), method="euclidian")
fit <- hclust(d=d, method="complete")   # for a different look try substituting: method="ward.D"
fit
plot(fit, hang=-1) #plot
plot.new() #find number of clusters
plot(fit, hang=-1)
groups <- cutree(fit, k=3)   # "k=" defines the number of clusters you are using
rect.hclust(fit, k=3, border="red") # draw dendogram with red borders around the 6 clusters
# K-means
library(fpc)
library(cluster)
dtms <- removeSparseTerms(dtm, 0.15)
d <- dist(t(dtms), method="manhattan")
kfit <- kmeans(d, 2)
clusplot(as.matrix(d), kfit$cluster, color=T, shade=T, labels=2, lines=0)
# HDBSCAN
library(dbscan)
dtms <- removeSparseTerms(dtm, 0.15)
d <- dist(t(dtms), method="manhattan")
kfit <- dbscan(d, 2)
clusplot(as.matrix(d), kfit$cluster, color=T, shade=T, labels=2, lines=0)
# EM
library(mixtools)
dtms <- removeSparseTerms(dtm, 0.15)
d <- dist(t(dtms), method="manhattan")
gm<-normalmixEM(d,k=2, lambda=c(0.7,0.3), mu=c(0.5,2),sigma=c(2,0.8))
plot(gm)
clusplot(as.matrix(d), gm$posterior, color=T, shade=T, labels=2, lines=0)
ellipse(gm$mu, gm$sigma, alpha = .05, npoints = 250, newplot = FALSE,
draw = TRUE)
###
###
#plot(as.matrix(d), col=scales::alpha(gm$posterior,0.3), pch=20, xlim=c(-12,10),ylim=c(-12,12)) #plotting data
par(new=TRUE) #to include the previous plot on the previous = combine plots
mu1 = gm$mu[1]
mu2 = gm$mu[2]
sigma1 = gm$sigma[1]
sigma2 = gm$sigma[2]
points(mu1[1], mu1[2], pch=18, cex=1, col="steelblue")
points(mu2[1], mu2[2], pch=18, cex=1, col="yellowgreen")
car::ellipse(center=(mu1),shape=sigma1, radius=3, col="steelblue")
car::ellipse(center=as.vector(gm$mu),shape=gm$sigma[2], radius=3, col="yellowgreen")
# HDBSCAN
library(dbscan)
dtms <- removeSparseTerms(dtm, 0.15)
d <- dist(t(dtms), method="manhattan")
kfit <- dbscan(d, 2)
clusplot(as.matrix(d), kfit$cluster, color=T, shade=T, labels=2, lines=0)
kfit <- dbscan(d, 3)
clusplot(as.matrix(d), kfit$cluster, color=T, shade=T, labels=2, lines=0)
library(dbscan)
dtms <- removeSparseTerms(dtm, 0.15)
d <- dist(t(dtms), method="manhattan")
kfit <- hdbscan(d, 3)
clusplot(as.matrix(d), kfit$cluster, color=T, shade=T, labels=2, lines=0)
kfit <- hdbscan(d, 7)
clusplot(as.matrix(d), kfit$cluster, color=T, shade=T, labels=2, lines=0)
kfit <- hdbscan(d, 2)
clusplot(as.matrix(d), kfit$cluster, color=T, shade=T, labels=2, lines=0)
clusplot(as.matrix(d), kfit$cluster, color=T, shade=T, labels=4, lines=0)
clusplot(as.matrix(d), kfit$cluster, color=T, shade=T, labels=6, lines=0)
clusplot(as.matrix(d), kfit$cluster, color=T, shade=T, labels=7, lines=0)
clusplot(as.matrix(d), kfit$cluster, color=T, shade=T, labels=5, lines=0)
clusplot(as.matrix(d), kfit$cluster, color=T, shade=T, labels=4, lines=0)
clusplot(as.matrix(d), kfit$cluster, color=T, shade=T, labels=4, lines=0)
kfit <- dbscan(d, 2)
clusplot(as.matrix(d), kfit$cluster, color=T, shade=T, labels=4, lines=0)
d = proxy::dist(as.matrix(t(dtms)), method = "cosine")
kfit <- kmeans(d, 2)
clusplot(as.matrix(d), kfit$cluster, color=T, shade=T, labels=2, lines=0)
d <- dist(t(dtms), method="manhattan")
#d = proxy::dist(as.matrix(t(dtms)), method = "cosine")
kfit <- kmeans(d, 2)
clusplot(as.matrix(d), kfit$cluster, color=T, shade=T, labels=2, lines=0)
clusplot(as.matrix(d), kfit$cluster, color=T, shade=T, labels=1, lines=0)
kfit <- dbscan(d, 3)
clusplot(as.matrix(d), kfit$cluster, color=T, shade=T, labels=4, lines=0)
#d = proxy::dist(as.matrix(t(dtms)), method = "cosine")
kfit <- kmeans(d, 3)
clusplot(as.matrix(d), kfit$cluster, color=T, shade=T, labels=1, lines=0)
clusplot(as.matrix(d), kfit$cluster, color=T, shade=T, labels=2, lines=0)
d = proxy::dist(as.matrix(t(dtms)), method = "cosine")
kfit <- kmeans(d, 3)
clusplot(as.matrix(d), kfit$cluster, color=T, shade=T, labels=2, lines=0)
d <- dist(t(dtms), method="euclidian")
kfit <- kmeans(d, 3)
clusplot(as.matrix(d), kfit$cluster, color=T, shade=T, labels=2, lines=0)
# HDBSCAN
library(dbscan)
dtms <- removeSparseTerms(dtm, 0.15)
d = proxy::dist(as.matrix(t(dtms)), method = "cosine")
kfit <- dbscan(d, 3)
clusplot(as.matrix(d), kfit$cluster, color=T, shade=T, labels=4, lines=0)
kfit <- dbscan(d, 2)
clusplot(as.matrix(d), kfit$cluster, color=T, shade=T, labels=4, lines=0)
kfit <- dbscan(d, 5)
clusplot(as.matrix(d), kfit$cluster, color=T, shade=T, labels=4, lines=0)
# HDBSCAN
library(dbscan)
dtms <- removeSparseTerms(dtm, 0.15)
d <- dist(t(dtms), method="manhattan")
d = proxy::dist(as.matrix(t(dtms)), method = "cosine")
kfit <- dbscan(d, 5)
clusplot(as.matrix(d), kfit$cluster, color=T, shade=T, labels=4, lines=0)
kfit <- dbscan(d, 2)
clusplot(as.matrix(d), kfit$cluster, color=T, shade=T, labels=4, lines=0)
d <- dist(t(dtms), method="manhattan")
kfit <- dbscan(d, 2)
clusplot(as.matrix(d), kfit$cluster, color=T, shade=T, labels=4, lines=0)
kfit <- hdbscan(d, 2)
clusplot(as.matrix(d), kfit$cluster, color=T, shade=T, labels=4, lines=0)
kfit <- hdbscan(d, 3)
clusplot(as.matrix(d), kfit$cluster, color=T, shade=T, labels=4, lines=0)
kfit <- hdbscan(d, 2)
clusplot(as.matrix(d), kfit$cluster, color=T, shade=T, labels=4, lines=0)
clusplot(as.matrix(d), kfit$cluster, color=T, shade=T, labels=2, lines=0)
kfit <- hdbscan(d, 3)
clusplot(as.matrix(d), kfit$cluster, color=T, shade=T, labels=2, lines=0)
kfit <- hdbscan(d, 5)
clusplot(as.matrix(d), kfit$cluster, color=T, shade=T, labels=2, lines=0)
kfit <- hdbscan(d, 6)
clusplot(as.matrix(d), kfit$cluster, color=T, shade=T, labels=2, lines=0)
kfit <- hdbscan(d, 10)
clusplot(as.matrix(d), kfit$cluster, color=T, shade=T, labels=2, lines=0)
kfit <- kmeans(d, 4)
clusplot(as.matrix(d), kfit$cluster, color=T, shade=T, labels=2, lines=0)
library(cluster)
d <- dist(t(dtmss), method="euclidian")
fit <- hclust(d=d, method="complete")   # for a different look try substituting: method="ward.D"
fit
plot(fit, hang=-1) #plot
plot.new() #find number of clusters
plot(fit, hang=-1)
groups <- cutree(fit, k=3)   # "k=" defines the number of clusters you are using
rect.hclust(fit, k=3, border="red") # draw dendogram with red borders around the 6 clusters
# K-means
library(fpc)
library(cluster)
dtms <- removeSparseTerms(dtm, 0.15)
d <- dist(t(dtms), method="euclidian")
d = proxy::dist(as.matrix(t(dtms)), method = "cosine")
kfit <- kmeans(d, 4)
clusplot(as.matrix(d), kfit$cluster, color=T, shade=T, labels=2, lines=0)
d <- dist(t(dtms), method="manhattan")
kfit <- kmeans(d, 4)
clusplot(as.matrix(d), kfit$cluster, color=T, shade=T, labels=2, lines=0)
kfit <- hdbscan(d, 2)
clusplot(as.matrix(d), kfit$cluster, color=T, shade=T, labels=2, lines=0)
library(cluster)
d <- dist(t(dtmss), method="euclidian")
fit <- hclust(d=d, method="ward.D")   # for a different look try substituting: method="ward.D"
fit
plot(fit, hang=-1) #plot
plot.new() #find number of clusters
plot(fit, hang=-1)
groups <- cutree(fit, k=3)   # "k=" defines the number of clusters you are using
rect.hclust(fit, k=3, border="red") # draw dendogram with red borders around the 6 clusters
gm<-mvnormalmixEM(matrix(d),k=2, lambda=c(0.7,0.3), mu=c(0.5,2),sigma=c(2,0.8))
d
as.matrix(dist)
as.matrix(d)
gm<-mvnormalmixEM(as.matrix(d),k=2, lambda=c(0.7,0.3), mu=c(0.5,2),sigma=c(2,0.8))
gm<-normalmixEM(as.matrix(d),k=2, lambda=c(0.7,0.3), mu=c(0.5,2),sigma=c(2,0.8))
plot(gm)
clusplot(as.matrix(d), gm$posterior, color=T, shade=T, labels=2, lines=0)
gm<-normalmixEM((d),k=2, lambda=c(0.7,0.3), mu=c(0.5,2),sigma=c(2,0.8))
posterior
gm$posterior
plot(as.matrix(D))
plot(as.matrix(d))
plot(as.matrix(d)[2])
plot(as.matrix(d)[3])
plot(as.matrix(d)[3,])
plot(as.matrix(d)[])
plot(as.matrix(d))
gm<-normalmixEM((d),k=2, epsilon = 1e-3, lambda=c(0.7,0.3))
library(mixtools)
dtms <- removeSparseTerms(dtm, 0.15)
d <- dist(t(dtms), method="manhattan")
#gm<-normalmixEM((d),k=2, lambda=c(0.7,0.3), mu=c(0.5,2),sigma=c(2,0.8))
gm<-normalmixEM((d),k=2, epsilon = 1e-3, lambda=c(0.7,0.3))
plot.mixEM(gm)
plot.mixEM(gm, whichplots = 2)
length(d)
as.matrix(gm$posterior)
dim(as.matrix(gm$posterior))
dim(as.matrix(d))
#gm<-normalmixEM((d),k=2, lambda=c(0.7,0.3), mu=c(0.5,2),sigma=c(2,0.8))
gm<-mvnormalmixEM((d),k=2, epsilon = 1e-3, lambda=c(0.7,0.3))
# HDBSCAN
library(dbscan)
dtms <- removeSparseTerms(dtm, 0.15)
d <- dist(t(dtms), method="manhattan")
d = proxy::dist(as.matrix(t(dtms)), method = "cosine")
kfit <- hdbscan(d, 2)
clusplot(as.matrix(d), kfit$cluster, color=T, shade=T, labels=2, lines=0)
kfit <- hdbscan(d, 3)
clusplot(as.matrix(d), kfit$cluster, color=T, shade=T, labels=2, lines=0)
kfit <- hdbscan(d, 4)
clusplot(as.matrix(d), kfit$cluster, color=T, shade=T, labels=2, lines=0)
kfit <- hdbscan(d, 5)
clusplot(as.matrix(d), kfit$cluster, color=T, shade=T, labels=2, lines=0)
kfit <- hdbscan(d, 2)
clusplot(as.matrix(d), kfit$cluster, color=T, shade=T, labels=2, lines=0)
kfit <- hdbscan(d, 3)
clusplot(as.matrix(d), kfit$cluster, color=T, shade=T, labels=2, lines=0)
d <- dist(t(dtms), method="manhattan")
kfit <- hdbscan(d, 3)
clusplot(as.matrix(d), kfit$cluster, color=T, shade=T, labels=2, lines=0)
kfit <- hdbscan(d, 2)
clusplot(as.matrix(d), kfit$cluster, color=T, shade=T, labels=2, lines=0)
kfit <- hdbscan(d, 3)
clusplot(as.matrix(d), kfit$cluster, color=T, shade=T, labels=2, lines=0)
kfit <- hdbscan(d, 1.5)
kfit <- hdbscan(d, 3.5)
clusplot(as.matrix(d), kfit$cluster, color=T, shade=T, labels=2, lines=0)
kfit <- hdbscan(d, 2.5)
clusplot(as.matrix(d), kfit$cluster, color=T, shade=T, labels=2, lines=0)
kfit <- hdbscan(d, 1.9)
kfit <- hdbscan(d, 2.1)
clusplot(as.matrix(d), kfit$cluster, color=T, shade=T, labels=2, lines=0)
kfit <- hdbscan(d, 1)
kfit <- hdbscan(d, 2.9)
clusplot(as.matrix(d), kfit$cluster, color=T, shade=T, labels=2, lines=0)
(d, 2)
kfit <- hdbscan(d, 2)
?clusplot
clusplot(as.matrix(d), kfit$cluster, color=T, shade=T, labels=2, lines=0, main = 'HDBSCAN eps. 2 manhattan')
clusplot(as.matrix(d), kfit$cluster, color=T, shade=T, labels=2, lines=0, main = '4-means manhattan')
kfit <- kmeans(d, 4)
clusplot(as.matrix(d), kfit$cluster, color=T, shade=T, labels=2, lines=0, main = '4-means manhattan')
docs <- tm_map(docs, removeWords, c("white", "black", "thats", "just"))   #remove particular words
# this is demo script for text data mining
#
# clear everything
rm(list=ls())
set.seed(1337)
packages_used = c("rstudioapi", "tm")
for(package in packages_used){
if(package %in% rownames(installed.packages()) == FALSE) {
install.packages(package)
}
}
setwd_current_path = function(){
library(rstudioapi)
current_path = getActiveDocumentContext()$path
setwd(dirname(current_path)) #get this current folder
print(getwd())
}
setwd_current_path()
cname <- file.path("./Data/Text/")
dir(cname) #check loaded texts
# load package tm  which is framework for text data mining / NLP
library(tm)
# load available documents
docs <- VCorpus(DirSource(cname))   #corpus or set of texts
#print(summary(docs))
inspect(docs[2]) #some data about a loaded text - order 2
writeLines(as.character(docs[2])) #content of text 2
# Preprocessing
docs <- tm_map(docs,removePunctuation)   #remove punctuation symbols
docs <- tm_map(docs, removeNumbers)   #remove numbers
docs <- tm_map(docs, tolower)   #remove capitalization - to lowcase
docs <- tm_map(docs, removeWords, c("the", "and", stopwords("english")))   #remove common words such as "a, and, also, the"
docs <- tm_map(docs, removeWords, c("white", "black", "thats", "just"))   #remove particular words
docs <- tm_map(docs, stripWhitespace)  #remove whitespaces from previous eliminations
#for (j in seq(docs)) {
#  docs[[j]] <- gsub("????", " ", docs[[j]])  #not well translated character
#}
docs <- tm_map(docs, PlainTextDocument)   #prepare de document as text
#Work with the data
#we use a Document-Term Matrix (DTM) representation: documents as the rows, terms/words as the columns, frequency of the term in the document as the entries. Because the number of unique words in the corpus the dimension can be large.
dtm <- DocumentTermMatrix(docs)   #create document-term matrix
dim(dtm)
print(dtm)
tdm <- TermDocumentMatrix(docs)   #creating the transpose of dtm
print(tdm)
#exploring data
freq <- colSums(as.matrix(dtm))   #organize terms by frequency
length(freq)
head(table(freq), 10) #check the less occuring words - top number is frequency of appearing, bottom number the number of words
tail(table(freq), 10) #check the most occurring words
dtms <- removeSparseTerms(dtm, 0.1) #remove sparse - less frequent items, matrix that is only 10% empty space
print(dtms)
freq <- colSums(as.matrix(dtms))
freq
# table after removing sparse terms
freq <- colSums(as.matrix(dtms))
print(freq)
print(findFreqTerms(dtm, lowfreq=30)) #show words that appear 30 or more times
#plotting
# word frequencies
library(ggplot2)
wf <- data.frame(word=names(freq), freq=freq)
p <- ggplot(subset(wf, freq>50), aes(word, freq))
p <- p + geom_bar(stat="identity")
p <- p + theme(axis.text.x=element_text(angle=45, hjust=1))
print(p)
#or ordered...
p <- ggplot(subset(wf, freq>50), aes(x = reorder(word, -freq), y = freq)) +
geom_bar(stat = "identity") +
theme(axis.text.x=element_text(angle=45, hjust=1))
print(p)
#find correlations between terms
findAssocs(dtm, c("will" , "american"), corlimit=0.85) #find correlations between words
#cloud of words
library(SnowballC)
library(wordcloud)
library(RColorBrewer)
freq = data.frame(sort(colSums(as.matrix(dtm)), decreasing=TRUE))
wordcloud::wordcloud(rownames(freq), freq[,1], scale=c(4, .1), max.words=50, colors=brewer.pal(6, "Dark2")) #most frequently used 50 words
#plot words that occur at least 50 times
wordcloud::wordcloud(rownames(freq), freq[,1], scale=c(4, .1), min.freq=25, colors=brewer.pal(6, "Dark2"))  #words used at least 25 times or more
#clustering by term similarity
#hierarchical
dtmss <- removeSparseTerms(dtm, 0.15) # This makes a matrix that is only 15% empty space, maximum.
print(dtmss)
library(cluster)
d <- dist(t(dtmss), method="euclidian")
fit <- hclust(d=d, method="ward.D")   # for a different look try substituting: method="ward.D"
fit
plot(fit, hang=-1) #plot
plot.new() #find number of clusters
plot(fit, hang=-1)
groups <- cutree(fit, k=3)   # "k=" defines the number of clusters you are using
rect.hclust(fit, k=3, border="red") # draw dendogram with red borders around the 6 clusters
# K-means
library(fpc)
library(cluster)
dtms <- removeSparseTerms(dtm, 0.15)
d <- dist(t(dtms), method="manhattan")
d = proxy::dist(as.matrix(t(dtms)), method = "cosine")
kfit <- kmeans(d, 4)
clusplot(as.matrix(d), kfit$cluster, color=T, shade=T, labels=2, lines=0, main = '4-means manhattan')
d <- dist(t(dtms), method="manhattan")
#d = proxy::dist(as.matrix(t(dtms)), method = "cosine")
kfit <- kmeans(d, 4)
clusplot(as.matrix(d), kfit$cluster, color=T, shade=T, labels=2, lines=0, main = '4-means manhattan')
# EM
library(mixtools)
dtms <- removeSparseTerms(dtm, 0.15)
d <- dist(t(dtms), method="manhattan")
#gm<-normalmixEM((d),k=2, lambda=c(0.7,0.3), mu=c(0.5,2),sigma=c(2,0.8))
gm<-mvnormalmixEM((d),k=2, epsilon = 1e-3, lambda=c(0.7,0.3))
plot.mixEM(gm, whichplots = 2)
#gm<-normalmixEM((d),k=2, lambda=c(0.7,0.3), mu=c(0.5,2),sigma=c(2,0.8))
gm<-normalmixEM((d),k=2, epsilon = 1e-3, lambda=c(0.7,0.3))
plot.mixEM(gm, whichplots = 2)
#gm<-normalmixEM((d),k=2, lambda=c(0.7,0.3), mu=c(0.5,2),sigma=c(2,0.8))
gm<-mvnormalmixEM((d),k=2, epsilon = 1e-3, lambda=c(0.7,0.3))
pi1<-0.7  # 0.5
pi2<-0.3
#initial values for means
mu1<-matrix(c(sample(-10:0, 1),sample(-10:0, 1)),nrow=2) #random uniformly selected starting values
mu2<-matrix(c(sample(0:10, 1),sample(0:10, 1)),nrow=2) #random uniformly selected starting values
#initial values for covariance matrix for each cluster
#NB!! covariance matrix of sigmas, must be symmetric!!
sym1 = sample(-3:3, 1)
sym2 = sample(-3:3, 1)
sigma1<-matrix(c(sample(1:5, 1),sym1,sym1,sample(1:5, 1)),nrow=2)
sigma2<-matrix(c(sample(1:5, 1),sym2,sym2,sample(1:5, 1)),nrow=2)
gm<-mvnormalmixEM((d),k=2, epsilon = 1e-3, lambda=c(pi1,pi2), mu=c(mu1,mu2),sigma=c(sigma1,sigma2))
gm<-mvnormalmixEM((d),k=2, lambda=c(pi1,pi2), mu=c(mu1,mu2),sigma=c(sigma1,sigma2))
set.seed(100)
x.1 <- rmvnorm(40, c(0, 0))
x.2 <- rmvnorm(60, c(3, 4))
X.1 <- rbind(x.1, x.2)
mu <- list(c(0, 0), c(3, 4))
out.1 <- mvnormalmixEM(X.1, arbvar = FALSE, mu = mu,
epsilon = 1e-02)
out.1[2:5]
##Fitting randomly generated data with a 2-component scale mixture of bivariate normals.
x.3 <- rmvnorm(40, c(0, 0), sigma =
matrix(c(200, 1, 1, 150), 2, 2))
x.4 <- rmvnorm(60, c(0, 0))
X.2 <- rbind(x.3, x.4)
lambda <- c(0.40, 0.60)
sigma <- list(diag(1, 2), matrix(c(200, 1, 1, 150), 2, 2))
out.2 <- mvnormalmixEM(d, arbmean = FALSE,
sigma = sigma, lambda = lambda,
epsilon = 1e-02)
mu <- list(c(0, 0), c(3, 4))
lambda <- c(0.40, 0.60)
sigma <- list(diag(1, 2), matrix(c(200, 1, 1, 150), 2, 2))
gm <- mvnormalmixEM(d, arbmean = FALSE,
sigma = sigma, lambda = lambda,
epsilon = 1e-02)
length(mu)
nrow(sigma)
sigma
dim[sigma[1]]
dim[sigma
dim[sigma]
mu <- list(c(0, 0), c(3, 4))
lambda <- c(0.40, 0.60)
sigma <- list(sigma1, sigma2)
gm <- mvnormalmixEM(d, arbmean = FALSE,
sigma = sigma, lambda = lambda,
epsilon = 1e-02)
mu <- list(mu1, mu2)
lambda <- c(0.40, 0.60)
sigma <- list(sigma1, sigma2)
gm <- mvnormalmixEM(d, arbmean = FALSE,
sigma = sigma, lambda = lambda,
epsilon = 1e-02)
length(mu)
length(sigma)
gm <- mvnormalmixEM(d, sigma = sigma, lambda = lambda,
epsilon = 1e-02)
mu <- list(mu1, mu2)
lambda <- c(0.7, 0.3)
sigma <- list(sigma1, sigma2)
gm <- mvnormalmixEM(d, sigma = sigma, mu=mu lambda = lambda,
epsilon = 1e-03)
gm <- mvnormalmixEM(d, sigma = sigma, mu=mu, lambda = lambda,
epsilon = 1e-03)
gm <- mvnormalmixEM(d, sigma = sigmas, mu=mus, lambda = lambdas)
lambdas <- c(0.7, 0.3)
sigmas <- list(sigma1, sigma2)
mus <- list(mu1, mu2)
gm <- mvnormalmixEM(d, sigma = sigmas, mu=mus, lambda = lambdas)
gm <- mvnormalmixEM(x,k=2,epsilon=1e-04)
gm <- mvnormalmixEM(d,k=2,epsilon=1e-04)
gm <- mvnormalmixEM(d,k=2,epsilon=1e-04, maxit = 10000)
gm <- mvnormalmixEM(d,k=2,epsilon=1e-04, lambda=lambdas, maxit = 10000)
gm <- mvnormalmixEM(d,k=2,epsilon=1e-04, lambda=lambdas, sigma = sigmas, maxit = 10000)
gm <- mvnormalmixEM(d,k=2,epsilon=1e-04, lambda=lambdas, sigma = sigmas, mu = mus, maxit = 10000)
mus
sigmas
gm <- mvnormalmixEM(d,k=2,epsilon=1e-04, lambda=lambdas, sigma = sigmas, mu = t(mus), maxit = 10000)
t(mus)
mu1
#initial values for means
mu1<-t(matrix(c(sample(-10:0, 1),sample(-10:0, 1)),nrow=2)) #random uniformly selected starting values
mu2<-t(matrix(c(sample(0:10, 1),sample(0:10, 1)),nrow=2)) #random uniformly selected starting values
mu1
mus <- list(mu1, mu2)
lambdas <- c(0.7, 0.3)
sigmas <- list(sigma1, sigma2)
mus <- list(mu1, mu2)
lambdas <- c(0.7, 0.3)
sigmas <- list(sigma1, sigma2)
gm <- mvnormalmixEM(d,k=2,epsilon=1e-04, lambda=lambdas, sigma = sigmas, mu = mus, maxit = 10000)
mus
sigmas
gm <- mvnormalmixEM(d,k=2,epsilon=1e-04, sigma = sigmas, mu = mus, maxit = 10000)
gm <- mvnormalmixEM(d,k=2,epsilon=1e-04, mu = mus, maxit = 10000)
gm <- mvnormalmixEM(d,k=2, mu = mus, maxit = 10000)
gm <- mvnormalmixEM(as.matrix(d),k=2, mu = mus, maxit = 10000)
gm <- mvnormalmixEM(d,k=97, mu = mus, maxit = 10000)
gm <- mvnormalmixEM(d,k=2, mu = mus, maxit = 10000)
gm <- mvnormalmixEM(d,k=3, mu = mus, maxit = 10000)
gm <- mvnormalmixEM(d,k=2, mu = mus, maxit = 10000)
gm <- mvnormalmixEM(d,k=2, lambda = lambdas, maxit = 10000)
gm <- mvnormalmixEM(as.matrix(d),k=2, lambda = lambdas, maxit = 10000)
as.matrix(d)
d
dtms <- removeSparseTerms(dtm, 0.15)
d <- dist(t(dtms), method="manhattan")
#d = proxy::dist(as.matrix(t(dtms)), method = "cosine")
kfit <- pam(d, 4)
clusplot(as.matrix(d), kfit$cluster, color=T, shade=T, labels=2, lines=0, main = '4-means manhattan')
?pam
d <- dist(t(dtmss), method="manhattan")
fit <- hclust(d=d, method="ward.D")   # for a different look try substituting: method="ward.D"
fit
plot(fit, hang=-1) #plot
plot.new() #find number of clusters
plot(fit, hang=-1)
groups <- cutree(fit, k=4)   # "k=" defines the number of clusters you are using
rect.hclust(fit, k=4, border="red") # draw dendogram with red borders around the 6 clusters
